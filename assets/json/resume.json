{
  "basics": {
    "name": "Luben M. C. Cabezas",
    "position": "PhD Candidate in Statistics",
    "email": "lucruz45.cab@gmail.com",
    "url": "https://monoxido45.github.io/",
    "interests": "Uncertainty Quantification in ML, Statistical Learning, Non-Parametric Statistics"
  },
  "work": [
    {
      "name": "Statistical Machine Learning Lab - SMaLL, UFSCar",
      "position": "PhD researcher",
      "url": "http://www.small.ufscar.br/",
      "startDate": "2022-08-01",
      "summary": "Research focused on Conformal Prediction, Likelihood-Free Inference, Non-Parametric Inference, and Hypothesis Testing. Under supervision of Prof. Rafael Izbicki",
      "highlights": [
        "Developed LOCART, a novel locally adaptive conformal prediction method, published as a full-length paper in Information Sciences",
        "Local Calibration",
        "Designed and maintained accessible Python and R packages to implement research frameworks.",
        "Research funded by FAPESP (Grant 2022/08579-7)."
      ]
    },
    {
      "name": "Terranova (Brazilian Jurimetrics Association)",
      "position": " Statistics Intern",
      "url": "https://trnv.com.br/",
      "startDate": "2021-11-01",
      "endDate": "2022-06-01",
      "summary": "Developed and maintained internal R-based packages for data analysis and modeling."
    },
    {
      "name": "Statistical Machine Learning Lab - SMaLL, UFSCar",
      "position": "Research Assistant",
      "url": "http://www.small.ufscar.br/",
      "startDate": "2020-11-01",
      "endDate": "2021-11-01",
      "summary": "Undergraduate researcher at SMaLL, supervised by Rafael Izbicki. Developed new visualization techniques, feature importance metrics, and scoring methods for hierarchical clustering using phylogenetic probabilistic models.",
      "highlights": [
        "This work resulted in a full-length paper published in Applied Soft Computing (2023)",
        "Research funded by FAPESP (Grant 2020/10861-7)."
      ]
    }
  ],
  "education": [
    {
      "institution": "Federal University of SÃ£o Carlos and University of SÃ£o Paulo",
      "location": "SÃ£o Carlos, Brazil",
      "url": "https://www.pipges.ufscar.br",
      "area": "Statistics",
      "studyType": "PhD",
      "startDate": "2022-08-01",
      "GPA": "4.0/4.0",
      "courses": [
        "Advanced Probability",
        "Advanced Inference",
        "Statistical Learning",
        "Advanced Topics in Statistical Learning",
        "Stochastic Simulation"
      ]
    },
    {
      "institution": "Federal University of SÃ£o Carlos",
      "location": "SÃ£o Carlos, Brazil",
      "url": "https://www.des.ufscar.br",
      "area": "Statistics",
      "studyType": "Bachelor of Science",
      "startDate": "2018-03-01",
      "endDate": "2022-04-01",
      "GPA": "9.24/10.0",
      "courses": [
        "Probability",
        "Statistical Inference",
        "Bayesian Inference",
        "Machine Learning",
        "Regression analysis",
        "Stochastic Processes",
        "Computationally Intensive Methods"
      ]
    }
  ],
  "publications": [
    {
      "name": "Regression trees for fast and adaptive prediction intervals",
      "publisher": "Information Sciences",
      "releaseDate": "2025-01",
      "url": "https://www.sciencedirect.com/science/article/pii/S0020025524012830?via%3Dihub",
      "abstract": "In predictive modeling, quantifying prediction uncertainty is crucial for reliable decision-making. Traditional conformal inference methods provide marginally valid predictive regions but often produce non-adaptive intervals when naively applied to regression, potentially biasing applications. Recent advances using quantile regressors or conditional density estimators improve adaptability but are typically tied to specific prediction models, limiting their ability to quantify uncertainty around arbitrary models. Similarly, methods based on partitioning the feature space adopt sub-optimal strategies, failing to consistently measure predictive uncertainty across the feature space, especially in adversarial examples. This paper introduces a model-agnostic family of methods to calibrate prediction intervals for regression with local coverage guarantees. By leveraging regression trees and Random Forests, our approach constructs data-adaptive partitions of the feature space to approximate conditional coverage, enhancing the accuracy and scalability of prediction intervals. Our methods outperform established benchmarks on simulated and real-world datasets. They are implemented in the Python package clover, which integrates seamlessly with the scikit-learn interface for practical application."
    },
    {
      "name": "Hierarchical clustering: Visualization, feature importance and model selection",
      "publisher": "Applied Soft Computing",
      "releaseDate": "2023-07",
      "url": "https://www.sciencedirect.com/science/article/pii/S1568494623003216",
      "summary": "We propose methods for the analysis of hierarchical clustering that fully use the multi-resolution structure provided by a dendrogram. Specifically, we propose a loss for choosing between clustering methods, a feature importance score and a graphical tool for visualizing the segmentation of features in a dendrogram. Current approaches to these tasks lead to loss of information since they require the user to generate a single partition of the instances by cutting the dendrogram at a specified level. Our proposed methods, instead, use the full structure of the dendrogram. The key insight behind the proposed methods is to view a dendrogram as a phylogeny. This analogy permits the assignment of a feature value to each internal node of a tree through an evolutionary model. Real and simulated datasets provide evidence that our proposed framework has desirable outcomes and gives more insights than state-of-art approaches. We provide an R package that implements our methods."
    }
  ],
  "skills": [
    {
      "name": "Coding",
      "level": "Master",
      "icon": "fa-solid fa-hashtag",
      "keywords": [
        "R",
        "Python",
        "Shell Script"
      ]
    },
    {
      "name": "Coding",
      "level": "Master",
      "icon": "fa-solid fa-hashtag",
      "keywords": [
        "R",
        "Python",
        "Bash"
      ]
    }
  ],
  "languages": [
    {
      "language": "Portuguese",
      "fluency": "Native speaker",
      "icon": "ðŸ‡§ðŸ‡·"
    },
    {
      "language": "English",
      "fluency": "Fluent",
      "icon": "ðŸ‡¬ðŸ‡§"
    },
    {
      "language": "Spanish",
      "fluency": "Advanced",
      "icon": "ðŸ‡ªðŸ‡¸"
    },
    {
      "language": "French",
      "fluency": "Basic",
      "icon": "ðŸ‡«ðŸ‡·"
    }
  ],
  "interests": [
    {
      "name": "Statistical Learning",
      "icon": "fa-solid fa-tag",
      "keywords": [
        "Conformal Prediction",
        "Calibration",
        "Uncertainty Quantification",
        "Likelihood-Free Inference",
        "Neural Networks",
        "PAC Learning",
        "Decision Trees and Random Forests"
      ]
    },
    {
      "name": "Statistics",
      "icon": "fa-solid fa-tag",
      "keywords": [
        "Non Parameteric Inference",
        "Hypothesis Testing",
        "Bayesian Inference"
      ]
    }
  ]
}